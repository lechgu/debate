# LLM Debate System

A Python application where three LLMs (running in Docker via llama.cpp) debate a topic and rank each other's performance.

> **Note**: This project was fully generated by Claude Code.

## Setup

### 1. Download the Models

Create a directory for the models and download the required GGUF files:

```bash
mkdir -p ~/models/llama
cd ~/models/llama
```

Download the following models from Hugging Face:

**Alice - Google Gemma 3 12B:**
```bash
wget https://huggingface.co/lmstudio-community/gemma-3-12b-it-GGUF/resolve/main/google_gemma-3-12b-it-Q8_0.gguf
```

**Bob - GPT-OSS 20B:**
```bash
wget https://huggingface.co/mradermacher/GPT-OSS-20B-GGUF/resolve/main/GPT-OSS-20B.Q8_0.gguf -O gpt-oss-20b-Q8_0.gguf
```

**Charlie - Qwen3 14B:**
```bash
wget https://huggingface.co/mradermacher/Qwen3-14B-UD-GGUF/resolve/main/Qwen3-14B-UD.Q6_K_XL.gguf -O Qwen3-14B-UD-Q6_K_XL.gguf
```

> **Note**: These are large files (10-20GB each). Make sure you have sufficient disk space and a stable internet connection.

### 2. Start the LLM Containers

```bash
docker-compose up -d
```

This starts three LLM servers:
- **Alice** (port 9091): Google Gemma 3 12B
- **Bob** (port 9092): GPT-OSS 20B
- **Charlie** (port 9093): Qwen3 14B

### 3. Create and Activate Python Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Linux/macOS
# .venv\Scripts\activate   # On Windows
```

### 4. Install Python Dependencies

```bash
pip install -r requirements.txt
```

## Usage

Run the debate:

```bash
python debate.py
```

## How It Works

1. **Debate Phase**: All three LLMs discuss a predefined topic across multiple rounds
   - Round 1: Each LLM provides initial thoughts
   - Round 2+: LLMs respond to each other's arguments

2. **Ranking Phase**: Each LLM ranks all three participants (including themselves) based on:
   - Quality and depth of arguments
   - Clarity of communication
   - Logical reasoning
   - Persuasiveness

3. **Results**: The system aggregates rankings using a points system:
   - 1st place: 3 points
   - 2nd place: 2 points
   - 3rd place: 1 point

## Customization

Edit `debate.py` to change:
- The debate topic (line 245)
- Number of debate rounds (line 246)
- Temperature settings for creativity vs consistency
- Participant models and ports

## Example Output

```
================================================================================
DEBATE TOPIC: Should artificial intelligence development be regulated...
================================================================================

=== ROUND 1: Initial Statements ===

Alice:
[Alice's response]

Bob:
[Bob's response]

Charlie:
[Charlie's response]

=== ROUND 2: Responses and Rebuttals ===
...

================================================================================
RANKING PHASE: Each LLM ranks all participants
================================================================================

Alice's Rankings:
  1. Charlie - Strong logical arguments and clear structure
  2. Alice - Balanced perspective with good examples
  3. Bob - Valid points but less detailed

================================================================================
AGGREGATE SCORES
================================================================================

1. Charlie: 7 points
2. Alice: 6 points
3. Bob: 5 points
```

## Architecture

The application uses the OpenAI Python client configured to point to local llama.cpp servers, which provide an OpenAI-compatible API endpoint.

Each LLM:
- Maintains its own conversation history
- Receives context about other participants' statements
- Independently ranks all participants based on the full debate transcript
